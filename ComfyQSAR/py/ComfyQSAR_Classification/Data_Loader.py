import os
import pandas as pd
from rdkit import Chem
# from rdkit.Chem import SDWriter # SDWriter ëŠ” Load_and_Standardize, Standardization ì—ì„œë§Œ ì‚¬ìš©
# from ..utils.progress_utils import create_text_container # ì´ì œ progress_utilsì—ì„œ ê°€ì ¸ì˜´

# --- Common Utility Import ---
from server import PromptServer
import time # time ëª¨ë“ˆ ì¶”ê°€

# WebSocket ì´ë²¤íŠ¸ ì´ë¦„ ì •ì˜ (ëª¨ë“  QSAR ë…¸ë“œì—ì„œ ê³µí†µ ì‚¬ìš©)
QSAR_PROGRESS_EVENT = "qsar-desc-calc-progress" # ì´ë¦„ì„ ì¢€ ë” ë²”ìš©ì ìœ¼ë¡œ ë³€ê²½ (ì„ íƒì )
# ë˜ëŠ” ê¸°ì¡´ ì´ë¦„ ìœ ì§€: QSAR_DESC_CALC_PROGRESS_EVENT = "qsar-desc-calc-progress"

def send_progress(message, progress=None, node_id=None):
    """
    ì§€ì •ëœ ë©”ì‹œì§€ì™€ ì§„í–‰ë¥ (0-100)ì„ WebSocketì„ í†µí•´ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ì†¡í•˜ê³ ,
    ì¤‘ê°„ ë‹¨ê³„ ì—…ë°ì´íŠ¸ ì‹œ ì§§ì€ ì§€ì—° ì‹œê°„ì„ ì¶”ê°€í•˜ì—¬ UIì—ì„œ ë³¼ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    Args:
        message (str): í‘œì‹œí•  ìƒíƒœ ë©”ì‹œì§€.
        progress (Optional[float]): 0ë¶€í„° 100 ì‚¬ì´ì˜ ì§„í–‰ë¥  ê°’.
        node_id (Optional[str]): íŠ¹ì • ë…¸ë“œë¥¼ ëŒ€ìƒìœ¼ë¡œ í•  ê²½ìš° ë…¸ë“œ ID.
    """
    payload = {"text": [message]}
    is_intermediate_update = True # ì¤‘ê°„ ì—…ë°ì´íŠ¸ ì—¬ë¶€ í”Œë˜ê·¸

    if progress is not None:
        # ì§„í–‰ë¥  ê°’ì„ 0ê³¼ 100 ì‚¬ì´ë¡œ ì œí•œí•˜ê³  ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ (ì„ íƒì )
        clamped_progress = max(0.0, min(100.0, float(progress)))
        payload['progress'] = round(clamped_progress, 1)
        # 100%ê°€ ì•„ë‹Œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ì¸ì§€ í™•ì¸
        if clamped_progress < 100:
            is_intermediate_update = True

    # node ID ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í•„í„°ë§ ì‹œ ì‚¬ìš© ê°€ëŠ¥)
    if node_id:
        payload['node'] = node_id

    try:
        # PromptServer ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ë™ê¸°ì ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡
        PromptServer.instance.send_sync(QSAR_PROGRESS_EVENT, payload)

        # ì¤‘ê°„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ í›„ ì§§ì€ ì§€ì—° ì‹œê°„ ì¶”ê°€ (0.2ì´ˆ)
        # ìµœì¢…(100%) ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” ì§€ì—° ì—†ìŒ
        if is_intermediate_update:
            time.sleep(0.2) # 0.2ì´ˆ ëŒ€ê¸°

    except Exception as e:
        print(f"[ComfyQSAR Progress Util] WebSocket ì „ì†¡ ì˜¤ë¥˜: {e}")

# í•„ìš”ì— ë”°ë¼ ë‹¤ë¥¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ ê°€ëŠ¥ (ì˜ˆ: ì‹œê°„ í¬ë§·íŒ… ë“±) 

# í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ìƒì„± í—¬í¼ í•¨ìˆ˜
def create_text_container(*lines):
    # ê°€ì¥ ê¸´ ë¼ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„ì„  ê¸¸ì´ ê²°ì •
    max_length = max(len(line) for line in lines)
    separator = "=" * max_length
    
    # ì²« êµ¬ë¶„ì„  ì¶”ê°€
    result = [separator]
    
    # ê° ë¼ì¸ ì¶”ê°€
    for line in lines:
        result.append(line)
    
    # ë§ˆì§€ë§‰ êµ¬ë¶„ì„  ì¶”ê°€
    result.append(separator)
    
    # ì¤„ë°”ê¿ˆìœ¼ë¡œ ì¡°ì¸
    return "\n".join(result)

class Data_Loader_Classification:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "positive_file_path": ("STRING", 
                                       {"default": "",
                                        "placeholder": "positive.sdf, .csv or .smi",
                                        "tooltip": "Path to the positive file"}), # Added default examples
                "negative_file_path": ("STRING", 
                                       {"default": "",
                                        "placeholder": "negative.sdf, .csv or .smi",
                                        "tooltip": "Path to the negative file"}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING",)
    RETURN_NAMES = ("POSITIVE_PATH", "NEGATIVE_PATH",)
    FUNCTION = "load_data"
    CATEGORY = "QSAR/CLASSIFICATION/LOAD &STANDARDIZATION"
    OUTPUT_NODE = True

    def load_data(self, positive_file_path, negative_file_path):
        node_id = os.environ.get("NODE_ID")
        send_progress("ğŸš€ Starting Data Loading...", 0, node_id)
        output_dir = "QSAR/Load_Data" # Keep track of where outputs *might* go if processed later
        try:
            os.makedirs(output_dir, exist_ok=True)
            send_progress(f"ğŸ“‚ Output directory checked/created: {output_dir}", 5, node_id)

            # Check positive file
            send_progress(f"â³ Checking positive file: {positive_file_path}", 10, node_id)
            if not os.path.exists(positive_file_path):
                raise FileNotFoundError(f"Positive file not found: {positive_file_path}")
            if not (positive_file_path.endswith('.smi') or positive_file_path.endswith('.csv') or positive_file_path.endswith('.sdf')):
                raise ValueError("Unsupported positive file format. Use .smi, .csv, or .sdf.")
            send_progress("   Positive file format OK.", 15, node_id)

            # Check negative file
            send_progress(f"â³ Checking negative file: {negative_file_path}", 20, node_id)
            if not os.path.exists(negative_file_path):
                raise FileNotFoundError(f"Negative file not found: {negative_file_path}")
            if not (negative_file_path.endswith('.smi') or negative_file_path.endswith('.csv') or negative_file_path.endswith('.sdf')):
                raise ValueError("Unsupported negative file format. Use .smi, .csv, or .sdf.")
            send_progress("   Negative file format OK.", 25, node_id)

        except (FileNotFoundError, ValueError) as e:
            error_msg = f"âŒ Error checking input files: {str(e)}"
            send_progress(error_msg, None, node_id)
            return {"ui": {"text": create_text_container(error_msg)}, "result": ("", "")}


        # Function to count molecules (encapsulated)
        def count_molecules(file_path, file_type_label):
            send_progress(f"â³ Counting molecules in {file_type_label} file...", 30 if file_type_label == "positive" else 60, node_id)
            count = 0
            try:
                if file_path.endswith('.sdf'):
                    suppl = Chem.SDMolSupplier(file_path, removeHs=False, strictParsing=False)
                    count = sum(1 for mol in suppl if mol is not None)
                elif file_path.endswith('.smi'):
                    # Handle potential errors during read_csv
                    df = pd.read_csv(file_path, header=None)
                    count = len(df)
                elif file_path.endswith('.csv'):
                    df = pd.read_csv(file_path)
                    if "SMILES" not in df.columns:
                        raise ValueError(f"CSV file {file_path} must contain a 'SMILES' column")
                    count = len(df["SMILES"].dropna()) # Count non-NA SMILES
                send_progress(f"   Found {count} molecules in {file_type_label} file.", 50 if file_type_label == "positive" else 80, node_id)
                return count
            except Exception as e:
                raise ValueError(f"Error processing {file_type_label} file {file_path}: {str(e)}") from e

        try:
            # Count molecules
            pos_count = count_molecules(positive_file_path, "positive")
            neg_count = count_molecules(negative_file_path, "negative")
            total_count = pos_count + neg_count

            # Log message
            send_progress("ğŸ“ Generating summary...", 95, node_id)
            text_container_content = create_text_container(
                "ğŸ”¹ Classification Data Loaded! ğŸ”¹",
                f"âœ… Positive Compounds: {pos_count} (from {os.path.basename(positive_file_path)})",
                f"âœ… Negative Compounds: {neg_count} (from {os.path.basename(negative_file_path)})",
                f"ğŸ“Š Total Molecules Loaded: {total_count}",
            )
            send_progress("ğŸ‰ Data loading complete!", 100, node_id)

            return {
                "ui": {"text": text_container_content},
                "result": (str(positive_file_path), str(negative_file_path)) # Return original paths
            }

        except Exception as e:
            error_msg = f"âŒ Error counting molecules: {str(e)}"
            send_progress(error_msg, None, node_id)
            return {"ui": {"text": create_text_container(error_msg)}, "result": ("", "")}


class Standardization_Classification:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "positive_path": ("STRING", 
                                  {"default": "",
                                   "placeholder": "positive.sdf, .csv or .smi",
                                   "tooltip": "Path to the positive file"}),
                "negative_path": ("STRING", 
                                  {"default": "",
                                   "placeholder": "negative.sdf, .csv or .smi",
                                   "tooltip": "Path to the negative file"}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING",)
    RETURN_NAMES = ("POSITIVE_STD_PATH", "NEGATIVE_STD_PATH",) # Renamed for clarity
    FUNCTION = "standardize_data"
    CATEGORY = "QSAR/CLASSIFICATION/LOAD & STANDARDIZATION"
    OUTPUT_NODE = True
    
    def standardize_data(self, positive_path, negative_path):
        node_id = os.environ.get("NODE_ID")
        send_progress("ğŸš€ Starting Standardization...", 0, node_id)
        METAL_IONS = { # Define METAL_IONS inside the method or make it a class attribute
            'Li', 'Be', 'Na', 'Mg', 'Al', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',
            'Ga', 'Ge', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn',
            'Sb', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm',
            'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'Pa', 'U'
        }
        output_dir = "QSAR/Standardization"
        try:
            os.makedirs(output_dir, exist_ok=True)
            send_progress(f"ğŸ“‚ Output directory created/checked: {output_dir}", 5, node_id)
        except Exception as e:
            error_msg = f"âŒ Error creating output directory: {str(e)}"
            send_progress(error_msg, None, node_id)
            return {"ui": {"text": create_text_container(error_msg)}, "result": ("", "")}

        # Molecule filtering function (remains internal)
        def filter_molecule(mol):
            if mol is None: return False
            atom_symbols = {atom.GetSymbol() for atom in mol.GetAtoms()}
            if not atom_symbols or atom_symbols.issubset(METAL_IONS): return False # Handle empty or metal-only
            if len(Chem.GetMolFrags(mol)) > 1: return False
            return True

        # File processing function (now handles progress and errors better)
        def process_file(file_path, output_name, progress_start, progress_end):
            send_progress(f"â³ Standardizing {output_name} file: {os.path.basename(file_path)}...", progress_start, node_id)
            output_file = ""
            filtered_count = 0
            try:
                from rdkit.Chem import SDWriter # Import here to avoid global scope if not needed elsewhere

                if file_path.endswith('.sdf'):
                    suppl = Chem.SDMolSupplier(file_path, removeHs=True, strictParsing=False)
                    filtered_mols = [mol for mol in suppl if filter_molecule(mol)]
                    filtered_count = len(filtered_mols)
                    output_file = os.path.join(output_dir, f"{output_name}_standardized.sdf")
                    with SDWriter(output_file) as writer:
                        for mol in filtered_mols: writer.write(mol)

                elif file_path.endswith('.smi') or file_path.endswith('.csv'):
                    if file_path.endswith('.csv'):
                        df = pd.read_csv(file_path)
                        if "SMILES" not in df.columns:
                            raise ValueError(f"CSV file {file_path} must contain a 'SMILES' column")
                        smiles_col = "SMILES"
                    else: # .smi file
                        df = pd.read_csv(file_path, header=None, names=["SMILES"], skip_blank_lines=True)
                        smiles_col = "SMILES"

                    df["RDKit_Mol"] = df[smiles_col].apply(lambda x: Chem.MolFromSmiles(x) if pd.notna(x) else None)
                    filtered_df = df[df["RDKit_Mol"].apply(filter_molecule)].copy() # Use .copy()
                    filtered_df.drop(columns=["RDKit_Mol"], inplace=True)
                    filtered_count = len(filtered_df)

                    output_file = os.path.join(output_dir, f"{output_name}_standardized.csv")
                    filtered_df.to_csv(output_file, index=False)
                else:
                    raise ValueError(f"Unsupported file format: {file_path}")

                send_progress(f"   Finished standardizing {output_name}. Kept {filtered_count} molecules.", progress_end, node_id)
                return output_file, filtered_count

            except Exception as e:
                error_msg = f"âŒ Error standardizing {output_name} file ({os.path.basename(file_path)}): {str(e)}"
                # Don't send progress here, raise the exception to be caught outside
                send_progress(f"âŒ Error standardizing {output_name} file ({os.path.basename(file_path)}): {str(e)}", None, node_id)
                raise RuntimeError(error_msg) from e


        try:
            # Process files
            positive_output, pos_filtered_count = process_file(positive_path, "positive", 10, 50)
            negative_output, neg_filtered_count = process_file(negative_path, "negative", 55, 90)

            # Log message
            send_progress("ğŸ“ Generating summary...", 95, node_id)
            text_container_content = create_text_container(
                "ğŸ”¹ Standardization Completed! ğŸ”¹",
                f"âœ… Positive Molecules Standardized: {pos_filtered_count} (saved to {os.path.basename(positive_output)})",
                f"âœ… Negative Molecules Standardized: {neg_filtered_count} (saved to {os.path.basename(negative_output)})",
                f"ğŸ“Š Total Molecules After Standardization: {pos_filtered_count + neg_filtered_count}",
            )
            send_progress("ğŸ‰ Standardization finished successfully!", 100, node_id)

            return {
                "ui": {"text": text_container_content},
                "result": (str(positive_output), str(negative_output))
            }

        except Exception as e:
            # Error already contains details from process_file if it failed there
            error_msg = str(e)
            send_progress(error_msg, None, node_id)
            return {"ui": {"text": create_text_container(error_msg)}, "result": ("", "")}


class Load_and_Standardize_Classification:
    @classmethod
    def INPUT_TYPES(cls):
         return {
            "required": {
                "positive_file_path": ("STRING", 
                                       {"default": "",
                                        "placeholder": "positive.sdf .csv or .smi",
                                        "tooltip": "Path to the positive file"}),
                "negative_file_path": ("STRING", 
                                       {"default": "",
                                        "placeholder": "negative.sdf .csv or .smi",
                                        "tooltip": "Path to the negative file"}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING",)
    RETURN_NAMES = ("POSITIVE_STD_PATH", "NEGATIVE_STD_PATH",) # Renamed for clarity
    FUNCTION = "load_and_standardize"
    CATEGORY = "QSAR/CLASSIFICATION/LOAD & STANDARDIZATION"
    OUTPUT_NODE = True

    def load_and_standardize(self, positive_file_path, negative_file_path):
        node_id = os.environ.get("NODE_ID")
        send_progress("ğŸš€ Starting Load & Standardization...", 0, node_id)
        METAL_IONS = { # Define METAL_IONS inside the method or make it a class attribute
            'Li', 'Be', 'Na', 'Mg', 'Al', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',
            'Ga', 'Ge', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn',
            'Sb', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm',
            'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'Pa', 'U'
        }
        output_dir = "QSAR/Load_and_Standardize" # Different output dir
        try:
            os.makedirs(output_dir, exist_ok=True)
            send_progress(f"ğŸ“‚ Output directory created/checked: {output_dir}", 5, node_id)

            # --- File Checks (Copied from Data_Loader) ---
            send_progress(f"â³ Checking positive file: {positive_file_path}", 6, node_id)
            if not os.path.exists(positive_file_path):
                raise FileNotFoundError(f"Positive file not found: {positive_file_path}")
            if not (positive_file_path.endswith('.smi') or positive_file_path.endswith('.csv') or positive_file_path.endswith('.sdf')):
                raise ValueError("Unsupported positive file format. Use .smi, .csv, or .sdf.")
            send_progress("   Positive file format OK.", 7, node_id)

            send_progress(f"â³ Checking negative file: {negative_file_path}", 8, node_id)
            if not os.path.exists(negative_file_path):
                raise FileNotFoundError(f"Negative file not found: {negative_file_path}")
            if not (negative_file_path.endswith('.smi') or negative_file_path.endswith('.csv') or negative_file_path.endswith('.sdf')):
                raise ValueError("Unsupported negative file format. Use .smi, .csv, or .sdf.")
            send_progress("   Negative file format OK.", 10, node_id)
            # --- End File Checks ---

        except (FileNotFoundError, ValueError) as e:
            error_msg = f"âŒ Error checking input files: {str(e)}"
            send_progress(error_msg, None, node_id)
            return {"ui": {"text": create_text_container(error_msg)}, "result": ("", "")}

        # Molecule filtering function (internal)
        def filter_molecule(mol):
            if mol is None: return False
            atom_symbols = {atom.GetSymbol() for atom in mol.GetAtoms()}
            if not atom_symbols or atom_symbols.issubset(METAL_IONS): return False # Handle empty or metal-only
            if len(Chem.GetMolFrags(mol)) > 1: return False
            return True

        # File processing function (modified for Load & Standardize)
        def process_file(file_path, output_name, progress_start, progress_end):
            send_progress(f"â³ Loading & Standardizing {output_name} file: {os.path.basename(file_path)}...", progress_start, node_id)
            output_file = ""
            original_count = 0
            filtered_count = 0
            try:
                from rdkit.Chem import SDWriter # Import here

                if file_path.endswith('.sdf'):
                    suppl = Chem.SDMolSupplier(file_path, removeHs=True, strictParsing=False)
                    valid_molecules = []
                    # Iterate once to count originals and filter
                    for mol in suppl:
                         original_count += 1
                         if filter_molecule(mol):
                             valid_molecules.append(mol)
                    filtered_count = len(valid_molecules)
                    output_file = os.path.join(output_dir, f"{output_name}_standardized.sdf")
                    with SDWriter(output_file) as writer:
                        for mol in valid_molecules: writer.write(mol)

                elif file_path.endswith('.smi') or file_path.endswith('.csv'):
                    if file_path.endswith('.csv'):
                        df = pd.read_csv(file_path)
                        if "SMILES" not in df.columns:
                            raise ValueError(f"CSV file {file_path} must contain a 'SMILES' column")
                        smiles_col = "SMILES"
                    else: # .smi
                        df = pd.read_csv(file_path, header=None, names=["SMILES"], skip_blank_lines=True)
                        smiles_col = "SMILES"

                    original_count = len(df)
                    df["RDKit_Mol"] = df[smiles_col].apply(lambda x: Chem.MolFromSmiles(x) if pd.notna(x) else None)
                    filtered_df = df[df["RDKit_Mol"].apply(filter_molecule)].copy()
                    filtered_df.drop(columns=["RDKit_Mol"], inplace=True)
                    filtered_count = len(filtered_df)

                    output_file = os.path.join(output_dir, f"{output_name}_standardized.csv")
                    filtered_df.to_csv(output_file, index=False)
                else:
                    raise ValueError(f"Unsupported file format: {file_path}")

                send_progress(f"   Finished {output_name}. Original: {original_count}, Kept: {filtered_count}.", progress_end, node_id)
                return output_file, original_count, filtered_count

            except Exception as e:
                error_msg = f"âŒ Error processing {output_name} file ({os.path.basename(file_path)}): {str(e)}"
                send_progress(f"âŒ Error processing {output_name} file ({os.path.basename(file_path)}): {str(e)}", None, node_id)
                raise RuntimeError(error_msg) from e

        try:
            # Process files
            positive_output, pos_orig_count, pos_filtered_count = process_file(positive_file_path, "positive", 15, 50)
            negative_output, neg_orig_count, neg_filtered_count = process_file(negative_file_path, "negative", 55, 90)

            # Log message
            send_progress("ğŸ“ Generating summary...", 95, node_id)
            text_container_content = create_text_container(
                "ğŸ”¹ Load & Standardization Completed! ğŸ”¹",
                f"ğŸ“Š Original Counts:",
                f"  - Positive: {pos_orig_count}",
                f"  - Negative: {neg_orig_count}",
                f"  - Total: {pos_orig_count + neg_orig_count}",
                f"ğŸ“Š Counts After Standardization:",
                f"  - Positive: {pos_filtered_count} (saved to {os.path.basename(positive_output)})",
                f"  - Negative: {neg_filtered_count} (saved to {os.path.basename(negative_output)})",
                f"  - Total Kept: {pos_filtered_count + neg_filtered_count}",
            )
            send_progress("ğŸ‰ Load & Standardization finished successfully!", 100, node_id)

            return {
                "ui": {"text": text_container_content},
                "result": (str(positive_output), str(negative_output))
            }
        except Exception as e:
            error_msg = str(e) # Already formatted error message
            send_progress(error_msg, None, node_id)
            return {"ui": {"text": create_text_container(error_msg)}, "result": ("", "")}


NODE_CLASS_MAPPINGS = {
    "Data_Loader_Classification": Data_Loader_Classification,
    "Standardization_Classification": Standardization_Classification,
    "Load_and_Standardize_Classification": Load_and_Standardize_Classification,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Data_Loader_Classification": "Data Loader (Classification)",             # Updated display name
    "Standardization_Classification": "Standardization (Classification)",       # Updated display name
    "Load_and_Standardize_Classification": "Load & Standardization (Classification)", # Updated display name
}