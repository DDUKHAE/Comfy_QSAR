import os
import pandas as pd
import numpy as np
import itertools
import multiprocessing
from multiprocessing import Pool
from collections import defaultdict
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ëª¨ë“ˆ ë ˆë²¨ í•¨ìˆ˜ë¡œ ì´ë™ - ë©€í‹°í”„ë¡œì„¸ì‹±ì—ì„œ ì‚¬ìš©í•  í•¨ìˆ˜ë“¤
def evaluate_combination_cls(args):
    """
    ë‹¨ì¼ íŠ¹ì„± ì¡°í•©ì— ëŒ€í•œ ë¶„ë¥˜ ëª¨ë¸ í‰ê°€
    args: (X_subset, y, feature_comb)ì˜ íŠœí”Œ
    """
    X_subset, y, feature_comb = args
    X_train, X_eval, y_train, y_eval = train_test_split(X_subset, y, test_size=0.2, stratify=y, random_state=42)

    # ìŠ¤ì¼€ì¼ë§ ì ìš©
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_eval_scaled = scaler.transform(X_eval)

    # ë¬´í•œê°’, NaN ê²€ì‚¬ ë° ì²˜ë¦¬
    if np.isnan(X_train_scaled).any() or np.isinf(X_train_scaled).any():
        X_train_scaled = np.nan_to_num(X_train_scaled, nan=0.0, posinf=0.0, neginf=0.0)
    if np.isnan(X_eval_scaled).any() or np.isinf(X_eval_scaled).any():
        X_eval_scaled = np.nan_to_num(X_eval_scaled, nan=0.0, posinf=0.0, neginf=0.0)

    try:
        model = LogisticRegression(max_iter=1000)
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_eval_scaled)
        acc = accuracy_score(y_eval, y_pred)
    except Exception as e:
        print(f"ëª¨ë¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        acc = 0.0  # ì˜¤ë¥˜ ë°œìƒ ì‹œ 0ì  ì²˜ë¦¬
    
    return feature_comb, acc

class Feature_Combination_Search:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "input_file": ("STRING",),
                "max_features": ("INT", {"default": 5, "min": 1, "max": 100, "step": 1}),
                "num_cores": ("INT", {"default": 4, "min": 1, "max": 16, "step": 1}),
                "top_n": ("INT", {"default": 3, "min": 1, "max": 100, "step": 1})
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("BEST_FEATURE_SET",)
    FUNCTION = "find_best_combinations"
    CATEGORY = "QSAR/CLASSIFICATION/COMBINATION"
    OUTPUT_NODE = True
    
    def find_best_combinations(self, input_file, max_features, num_cores, top_n):
        """
        Find the best combinations of descriptors for classification model.
        """
        os.makedirs("QSAR/Combination", exist_ok=True)
        df = pd.read_csv(input_file)

        # ê²°ì¸¡ì¹˜ì™€ ë¬´í•œê°’ ì²˜ë¦¬
        df_processed = df.copy()
        
        # Label ì—´ ë¶„ë¦¬
        if "Label" not in df_processed.columns:
            raise ValueError("ë°ì´í„°ì…‹ì— 'Label' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë¬´í•œê°’ ë° NaN ì²˜ë¦¬
        for col in df_processed.columns:
            if col != "Label":
                df_processed[col] = df_processed[col].replace([np.inf, -np.inf], np.nan)
                if df_processed[col].isnull().any():
                    median_val = df_processed[col].median()
                    if np.isnan(median_val):  # ì—´ ì „ì²´ê°€ NaNì¸ ê²½ìš°
                        median_val = 0
                    df_processed[col] = df_processed[col].fillna(median_val)

        X = df_processed.drop(columns=["Label"]).values
        y = df_processed["Label"].values
        feature_names = df_processed.drop(columns=["Label"]).columns.tolist()

        all_results = []
        available_cores = min(num_cores, multiprocessing.cpu_count())
        print(f"ì´ {available_cores}ê°œì˜ ì½”ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        for num_features in range(1, max_features + 1):
            print(f"íŠ¹ì„± {num_features}ê°œ ì¡°í•© ë¶„ì„ ì¤‘...")
            feature_combinations = list(itertools.combinations(range(X.shape[1]), num_features))
            
            # ì‘ì—… ìˆ˜ê°€ ì ìœ¼ë©´ ë³‘ë ¬ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
            if len(feature_combinations) < 10:
                results = []
                for comb in feature_combinations:
                    result = evaluate_combination_cls((X[:, list(comb)], y, comb))
                    results.append(result)
            else:
                # ë©€í‹°í”„ë¡œì„¸ì‹± í’€ ìƒì„±
                task_args = [(X[:, list(comb)], y, comb) for comb in feature_combinations]
                
                try:
                    with Pool(processes=available_cores) as pool:
                        results = pool.map(evaluate_combination_cls, task_args)
                except Exception as e:
                    print(f"ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ëŒ€ì²´
                    results = []
                    for args in task_args:
                        result = evaluate_combination_cls(args)
                        results.append(result)
                
            for feature_comb, acc in results:
                all_results.append({
                    "Num_Features": len(feature_comb),
                    "Feature_Indices": feature_comb,
                    "Best Features": [feature_names[i] for i in feature_comb],
                    "Accuracy": acc
                })

        # íŠ¹ì„± ìˆ˜ë³„ ìµœì  ì¡°í•© ì°¾ê¸°
        best_per_feature_count = {}
        for n in range(1, max_features + 1):
            candidates = [res for res in all_results if res['Num_Features'] == n]
            if candidates:
                best_per_feature_count[n] = max(candidates, key=lambda x: x['Accuracy'])

        # íŠ¹ì„± ìˆ˜ë³„ ìµœì  ì¡°í•© ì €ì¥
        best_per_size_df = pd.DataFrame(best_per_feature_count.values())
        best_per_size_path = os.path.join("QSAR/Combination", "Best_combination_per_size.csv")
        best_per_size_df.to_csv(best_per_size_path, index=False)

        # ìƒìœ„ Nê°œ ìµœì  ì¡°í•© ì €ì¥
        optimal_feature_paths = []
        best_features = None
        
        # ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if not all_results:
            error_message = "íŠ¹ì„± ì¡°í•© í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            print(error_message)
            output_file = os.path.join("QSAR/Combination", "error.txt")
            with open(output_file, 'w') as f:
                f.write(error_message)
            return {
                "ui": {"text": error_message},
                "result": (str(output_file),)
            }
            
        for i, result in enumerate(sorted(all_results, key=lambda x: x["Accuracy"], reverse=True)[:top_n], start=1):
            selected_columns = result["Best Features"] + ["Label"]
            df_selected = df_processed[selected_columns]
            output_path = os.path.join("QSAR/Combination", f"Optimal_Feature_Set_rank{i}.csv")
            df_selected.to_csv(output_path, index=False)
            optimal_feature_paths.append(output_path)
            
            if i == 1:
                best_features = result["Best Features"]
                output_file = os.path.join("QSAR/Combination", "Best_Optimal_Feature_Set.csv")
                df_selected.to_csv(output_file, index=False)

        # ë¡œê·¸ ë©”ì‹œì§€ ìƒì„±
        best_result = sorted(all_results, key=lambda x: x["Accuracy"], reverse=True)[0]
        text_container = (
            "========================================\n"
            "ğŸ”¹ Classification Feature Combination Search Completed! ğŸ”¹\n"
            "========================================\n"
            f"âœ… Best Accuracy: {best_result['Accuracy']:.4f}\n"
            f"âœ… Optimal Feature Set: {best_features}\n"
            f"ğŸ“Š Number of Features: {len(best_features)}\n"
            f"ğŸ’¾ Saved Per-Size Best Combinations: {best_per_size_path}\n"
            f"ğŸ’¾ Saved Top Feature Set: {optimal_feature_paths[0]}\n"
            f"ğŸ” Total Combinations Evaluated: {len(all_results)}\n"
            "========================================"
        )

        return {
            "ui": {"text": text_container},
            "result": (str(output_file),)
        }

# ë…¸ë“œ ë“±ë¡
NODE_CLASS_MAPPINGS = {
    "Feature_Combination_Search": Feature_Combination_Search
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Feature_Combination_Search": "Feature Combination Search"
} 