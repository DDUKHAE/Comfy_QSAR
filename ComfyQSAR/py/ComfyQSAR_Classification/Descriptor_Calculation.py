import os
import pandas as pd
from padelpy import padeldescriptor
# from server import PromptServer # send_progressì—ì„œ ì‚¬ìš©í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ì§ì ‘ ì„í¬íŠ¸ ë¶ˆí•„ìš”
import json

# --- Common Utility Import ---
from server import PromptServer
import time # time ëª¨ë“ˆ ì¶”ê°€

# WebSocket ì´ë²¤íŠ¸ ì´ë¦„ ì •ì˜ (ëª¨ë“  QSAR ë…¸ë“œì—ì„œ ê³µí†µ ì‚¬ìš©)
QSAR_PROGRESS_EVENT = "qsar-desc-calc-progress" # ì´ë¦„ì„ ì¢€ ë” ë²”ìš©ì ìœ¼ë¡œ ë³€ê²½ (ì„ íƒì )
# ë˜ëŠ” ê¸°ì¡´ ì´ë¦„ ìœ ì§€: QSAR_DESC_CALC_PROGRESS_EVENT = "qsar-desc-calc-progress"

def send_progress(message, progress=None, node_id=None):
    """
    ì§€ì •ëœ ë©”ì‹œì§€ì™€ ì§„í–‰ë¥ (0-100)ì„ WebSocketì„ í†µí•´ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ì†¡í•˜ê³ ,
    ì¤‘ê°„ ë‹¨ê³„ ì—…ë°ì´íŠ¸ ì‹œ ì§§ì€ ì§€ì—° ì‹œê°„ì„ ì¶”ê°€í•˜ì—¬ UIì—ì„œ ë³¼ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    Args:
        message (str): í‘œì‹œí•  ìƒíƒœ ë©”ì‹œì§€.
        progress (Optional[float]): 0ë¶€í„° 100 ì‚¬ì´ì˜ ì§„í–‰ë¥  ê°’.
        node_id (Optional[str]): íŠ¹ì • ë…¸ë“œë¥¼ ëŒ€ìƒìœ¼ë¡œ í•  ê²½ìš° ë…¸ë“œ ID.
    """
    payload = {"text": [message]}
    is_intermediate_update = False # ì¤‘ê°„ ì—…ë°ì´íŠ¸ ì—¬ë¶€ í”Œë˜ê·¸

    if progress is not None:
        # ì§„í–‰ë¥  ê°’ì„ 0ê³¼ 100 ì‚¬ì´ë¡œ ì œí•œí•˜ê³  ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ (ì„ íƒì )
        clamped_progress = max(0.0, min(100.0, float(progress)))
        payload['progress'] = round(clamped_progress, 1)
        # 100%ê°€ ì•„ë‹Œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ì¸ì§€ í™•ì¸
        if clamped_progress < 100:
            is_intermediate_update = True

    # node ID ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í•„í„°ë§ ì‹œ ì‚¬ìš© ê°€ëŠ¥)
    # if node_id: payload['node'] = node_id

    try:
        # PromptServer ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ë™ê¸°ì ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡
        PromptServer.instance.send_sync(QSAR_PROGRESS_EVENT, payload)

        # ì¤‘ê°„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ í›„ ì§§ì€ ì§€ì—° ì‹œê°„ ì¶”ê°€ (0.2ì´ˆ)
        # ìµœì¢…(100%) ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” ì§€ì—° ì—†ìŒ
        if is_intermediate_update:
            time.sleep(0.2) # 0.2ì´ˆ ëŒ€ê¸°

    except Exception as e:
        print(f"[ComfyQSAR Progress Util] WebSocket ì „ì†¡ ì˜¤ë¥˜: {e}")

# í•„ìš”ì— ë”°ë¼ ë‹¤ë¥¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ ê°€ëŠ¥ (ì˜ˆ: ì‹œê°„ í¬ë§·íŒ… ë“±) 

# í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ìƒì„± í—¬í¼ í•¨ìˆ˜
def create_text_container(*lines):
    # ê°€ì¥ ê¸´ ë¼ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„ì„  ê¸¸ì´ ê²°ì •
    max_length = max(len(line) for line in lines)
    separator = "=" * max_length
    
    # ì²« êµ¬ë¶„ì„  ì¶”ê°€
    result = [separator]
    
    # ê° ë¼ì¸ ì¶”ê°€
    for line in lines:
        result.append(line)
    
    # ë§ˆì§€ë§‰ êµ¬ë¶„ì„  ì¶”ê°€
    result.append(separator)
    
    # ì¤„ë°”ê¿ˆìœ¼ë¡œ ì¡°ì¸
    return "\n".join(result)

# --- Helper Functions ---
# send_progress í•¨ìˆ˜ ì •ì˜ ì œê±°

class Descriptor_Calculations_Classification:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "positive_path": ("STRING",),
                "negative_path": ("STRING",),
                "advanced": ("BOOLEAN", {"default": False}),
            },
            "optional": {
                "descriptor_type": (["2D", "3D"], {"default": "2D"}),
                "detect_aromaticity": ("BOOLEAN", {"default": True}),
                "remove_salt": ("BOOLEAN", {"default": True}),
                "standardize_nitro": ("BOOLEAN", {"default": True}),
                "use_file_name_as_molname": ("BOOLEAN", {"default": True}),
                "retain_order": ("BOOLEAN", {"default": True}),
                "threads": ("INT", {"default": -1, "min": -1, "max": 64, "step": 1}),
                "waiting_jobs": ("INT", {"default": -1, "min": -1, "max": 64, "step": 1}),
                "max_runtime": ("INT", {"default": 10000, "min": 1000, "max": 100000, "step": 1000}),
                "max_cpd_per_file": ("INT", {"default": 0, "min": 0, "max": 100000, "step": 1000}),
                "headless": ("BOOLEAN", {"default": True}),
                "log": ("BOOLEAN", {"default": True}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("DESCRIPTORS_PATH",)
    FUNCTION = "calculate_and_merge_descriptors"
    CATEGORY = "QSAR/CLASSIFICATION/CALCULATION"
    OUTPUT_NODE = True # UI ì¶œë ¥ì„ ìœ„í•´ True ìœ ì§€

    def calculate_and_merge_descriptors(self, positive_path, negative_path, descriptor_type, detect_aromaticity, remove_salt, standardize_nitro, use_file_name_as_molname, retain_order, threads, waiting_jobs, max_runtime, max_cpd_per_file, headless, log, advanced):

        # --- ì „ì²´ ë‹¨ê³„ë³„ ì§„í–‰ë¥  í• ë‹¹ (ì˜ˆì‹œ) ---
        PREPARE_PCT = 5
        PROCESS_POS_PCT = 40
        PROCESS_NEG_PCT = 40
        MERGE_SAVE_PCT = 15
        # í•©ê³„ = 100

        current_progress = 0
        # ì´ì œ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
        send_progress("ğŸš€ Starting descriptor calculation...", current_progress)

        # --- 1. ì´ˆê¸° ì„¤ì • ë° ë””ë ‰í† ë¦¬ ìƒì„± ---
        output_dir = "QSAR/Descriptor_Calculation"
        os.makedirs(output_dir, exist_ok=True)
        current_progress = PREPARE_PCT
        send_progress(f"ğŸ“‚ Output directory prepared: {output_dir}", current_progress)

        # PaDEL ì˜µì…˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        padel_options = {
            "d_2d": descriptor_type == "2D",
            "d_3d": descriptor_type == "3D",
            "detectaromaticity": detect_aromaticity,
            "removesalt": remove_salt,
            "standardizenitro": standardize_nitro,
            "usefilenameasmolname": use_file_name_as_molname,
            "retainorder": retain_order,
            "threads": threads,
            "waitingjobs": waiting_jobs,
            "maxruntime": max_runtime,
            "maxcpdperfile": max_cpd_per_file,
            "headless": headless,
            "log": log,
        }

        # --- 2. ë‚´ë¶€ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ ---
        def process_file(input_path, tag, label, progress_start, progress_total_allocation):
            """ì£¼ì–´ì§„ íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  í•´ë‹¹ ë‹¨ê³„ ë‚´ì—ì„œì˜ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""

            # ë‹¨ê³„ë³„ ì˜ˆìƒ ê°€ì¤‘ì¹˜
            READ_CHECK_WEIGHT = 10
            PADEL_WEIGHT = 80
            LABEL_SAVE_WEIGHT = 10

            def update_sub_progress(sub_step_progress, message):
                """ì „ì²´ ì§„í–‰ë¥  ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸"""
                new_progress = progress_start + (sub_step_progress / 100.0) * progress_total_allocation
                # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©
                send_progress(message, new_progress)


            base_message = f"â³ Processing {tag} file: {os.path.basename(input_path)}..."
            # update_sub_progress(0, base_message)

            mol_dir_for_padel = input_path
            smiles_path = None
            desc_file = os.path.join(output_dir, f"{tag}_descriptors.csv")

            try:
                # 1. íŒŒì¼ ì½ê¸° ë° í™•ì¸
                sub_progress = 0
                if input_path.endswith('.sdf'):
                    update_sub_progress(sub_progress + READ_CHECK_WEIGHT * 0.5, f"   Format: SDF. Using directly.")
                    mol_dir_for_padel = input_path
                elif input_path.endswith(('.csv', '.smi')):
                    update_sub_progress(sub_progress + READ_CHECK_WEIGHT * 0.2, f"   Format: {input_path.split('.')[-1]}. Reading SMILES...")
                    try:
                        df = pd.read_csv(input_path)
                        if "SMILES" not in df.columns: raise ValueError(f"âŒ SMILES column not found: {input_path}")
                    except Exception as read_e: raise ValueError(f"âŒ Error reading file {input_path}: {read_e}")
                    smiles_path = os.path.join(output_dir, f"{tag}_smiles_temp.smi")
                    df[["SMILES"]].to_csv(smiles_path, index=False, header=False)
                    update_sub_progress(sub_progress + READ_CHECK_WEIGHT, f"   Created temporary SMILES file: {smiles_path}")
                    mol_dir_for_padel = smiles_path
                else: raise ValueError(f"Unsupported file format: {input_path}")
                sub_progress += READ_CHECK_WEIGHT

                # 2. PaDEL ì‹¤í–‰
                update_sub_progress(sub_progress + PADEL_WEIGHT * 0.05, f"   Running PaDEL-Descriptor for {tag}...")
                padeldescriptor(mol_dir=mol_dir_for_padel, d_file=desc_file, **padel_options)
                sub_progress += PADEL_WEIGHT
                update_sub_progress(sub_progress, f"   PaDEL finished for {tag}. Output: {desc_file}")

                if not os.path.exists(desc_file): raise FileNotFoundError(f"âŒ Descriptor file not created: {desc_file}")

                # 3. ë¼ë²¨ ì¶”ê°€ ë° í›„ì²˜ë¦¬
                df_desc = pd.read_csv(desc_file)
                df_desc["Label"] = label
                sub_progress += LABEL_SAVE_WEIGHT * 0.5
                update_sub_progress(sub_progress, f"   Added 'Label' column ({label}) to {tag} descriptors.")
                update_sub_progress(100, f"   Finished processing {tag} file.")
                return df_desc

            finally:
                if smiles_path and os.path.exists(smiles_path):
                    os.remove(smiles_path)
                    # send_progress í˜¸ì¶œ ì œê±° (ì´ë¯¸ ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ë¨)

        # --- 3. ë©”ì¸ ì²˜ë¦¬ ë¡œì§ ---
        try:
            # Positive ë°ì´í„° ì²˜ë¦¬
            start_pos_progress = current_progress
            df_positive = process_file(positive_path, "positive", label=1, progress_start=start_pos_progress, progress_total_allocation=PROCESS_POS_PCT)
            current_progress = start_pos_progress + PROCESS_POS_PCT
            send_progress(f"âœ… Positive file processing complete. {len(df_positive)} molecules.", current_progress)

            # Negative ë°ì´í„° ì²˜ë¦¬
            start_neg_progress = current_progress
            df_negative = process_file(negative_path, "negative", label=0, progress_start=start_neg_progress, progress_total_allocation=PROCESS_NEG_PCT)
            current_progress = start_neg_progress + PROCESS_NEG_PCT
            send_progress(f"âœ… Negative file processing complete. {len(df_negative)} molecules.", current_progress)

            # ê²°ê³¼ ë³‘í•© ë° ì €ì¥
            merge_start_progress = current_progress
            merge_progress_allocation = 100 - merge_start_progress

            send_progress("ğŸ”— Merging positive and negative sets...", merge_start_progress + merge_progress_allocation * 0.2)
            df_final = pd.concat([df_positive, df_negative], ignore_index=True)
            send_progress("ğŸ’¾ Saving final merged descriptors...", merge_start_progress + merge_progress_allocation * 0.6)
            final_file = os.path.join(output_dir, "final_merged_descriptors.csv")
            df_final.to_csv(final_file, index=False)
            current_progress = 98
            send_progress(f"ğŸ“Š Total molecules processed: {len(df_final)}. File saved to: {final_file}", current_progress)

            # ìµœì¢… ê²°ê³¼ í…ìŠ¤íŠ¸ ìƒì„±
            text_container = create_text_container(
                    "ğŸ”¹ **Descriptor Calculation & Merge Done!** ğŸ”¹",
                    f"âœ… Positive Molecules: {len(df_positive)}",
                    f"âœ… Negative Molecules: {len(df_negative)}",
                    f"ğŸ“Š Total Molecules: {len(df_final)}",
                    "ğŸ“‚ Format: descriptors + Label column (1=positive, 0=negative)",
                    f"ğŸ’¾ Output File: {final_file}"
                )

            # ì™„ë£Œ ë©”ì‹œì§€ (100%)
            current_progress = 100
            send_progress("ğŸ‰ Calculation and merge finished successfully!", current_progress)

            # ìµœì¢… ê²°ê³¼ ë°˜í™˜
            return { "ui": {"text": text_container}, "result": (str(final_file),) }

        except Exception as e:
            error_message = f"âŒ **Descriptor Calculation Failed!** âŒ\nError: {str(e)}"
            send_progress(error_message) # ì‹¤íŒ¨ ì‹œ progress ì—†ì´
            error_container = create_text_container(
                "âŒ **Descriptor Calculation Failed!** âŒ",
                f"Error: {str(e)}"
            )
            return { "ui": {"text": error_container}, "result": (str(""),) }


# ë…¸ë“œ ë“±ë¡ (ê¸°ì¡´ê³¼ ë™ì¼)
NODE_CLASS_MAPPINGS = {
    "Descriptor_Calculations_Classification": Descriptor_Calculations_Classification
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Descriptor_Calculations_Classification": "Descriptor Calculation(Classification)"
} 