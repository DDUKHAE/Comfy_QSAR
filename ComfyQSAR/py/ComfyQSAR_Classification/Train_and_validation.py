import os
import pandas as pd
import joblib
from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score,
                             precision_score, recall_score)
from .Data_Loader import create_text_container

class Model_Validation_Classification:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "model_path": ("STRING",),
                "selected_descriptors_path": ("STRING",),
                "X_test_path": ("STRING",),
                "y_test_path": ("STRING",),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING",)
    RETURN_NAMES = ("EVALUATION_PATH", "PREDICTION_PATH",)
    FUNCTION = "validate_model"
    CATEGORY = "QSAR/CLASSIFICATION/VALIDATION"
    OUTPUT_NODE = True
    
    def validate_model(self, model_path, X_test_path, y_test_path, selected_descriptors_path):
        """
        Validate a trained classification model on the test set.
        """
        os.makedirs("QSAR/Validation", exist_ok=True)

        # ëª¨ë¸ ë¡œë“œ
        model = joblib.load(model_path)

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        X_test = pd.read_csv(X_test_path)            
        y_test = pd.read_csv(y_test_path)
        # ì„ íƒëœ ë””ìŠ¤í¬ë¦½í„° ë¡œë“œ
        with open(selected_descriptors_path, "r") as f:
            selected_features = [line.strip() for line in f.readlines()]

        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì„ íƒëœ íŠ¹ì„±ë§Œ ì‚¬ìš©
        X_test = X_test[selected_features]

        # ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred = model.predict(X_test)

        # í™•ë¥ ê°’ ì˜ˆì¸¡ ì‹œë„
        try:
            y_proba = model.predict_proba(X_test)[:, 1]
            test_roc_auc = roc_auc_score(y_test, y_proba)
        except Exception:
            y_proba = None
            test_roc_auc = None

        # ë¶„ë¥˜ ë©”íŠ¸ë¦­ ê³„ì‚°
        test_accuracy = accuracy_score(y_test, y_pred)
        test_f1 = f1_score(y_test, y_pred)
        test_precision = precision_score(y_test, y_pred)
        test_recall = recall_score(y_test, y_pred)
        test_specificity = recall_score(y_test, y_pred, pos_label=0) if len(set(y_test)) == 2 else None

        # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        pred_df = pd.DataFrame({"Actual": y_test, "Predicted": y_pred})
        
        # ì˜ˆì¸¡ í™•ë¥  ì¶”ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
        if y_proba is not None:
            pred_df["Probability"] = y_proba
            
        pred_csv_path = os.path.join("QSAR/Validation", "Actual_vs_Predicted.csv")
        pred_df.to_csv(pred_csv_path, index=False)

        # í‰ê°€ ì§€í‘œ ì €ì¥
        eval_data = {
            "Metric": ["Accuracy", "F1-Score", "Precision", "Recall (Sensitivity)", "Specificity"],
            "Value": [test_accuracy, test_f1, test_roc_auc, test_precision, test_recall, test_specificity]
        }
            
        eval_df = pd.DataFrame(eval_data)
        eval_csv_path = os.path.join("QSAR/Validation", "Evaluation_Results_TestSet.csv")
        eval_df.to_csv(eval_csv_path, index=False)

        # ë¡œê·¸ ë©”ì‹œì§€ ìƒì„±
        text_container = create_text_container(
            "ğŸ”¹ Classification Model Validation Done! ğŸ”¹",
            f"ğŸ“ Model: {model_path}",
            f"ğŸ“Š Accuracy: {test_accuracy:.4f}",
            f"ğŸ“Š F1 Score: {test_f1:.4f}",
            f"ğŸ“Š ROC-AUC: {test_roc_auc:.4f}" if test_roc_auc is not None else "ğŸ“Š ROC-AUC: Not Available",
            f"ğŸ“Š Precision: {test_precision:.4f}",
            f"ğŸ“Š Recall (Sensitivity): {test_recall:.4f}",
            f"ğŸ“Š Specificity: {test_specificity:.4f}" if test_specificity is not None else "ğŸ“Š Specificity: Not Available",
        )

        return {
            "ui": {"text": text_container},
            "result": (str(eval_csv_path), str(pred_csv_path),)
        }

# ë…¸ë“œ ë“±ë¡
NODE_CLASS_MAPPINGS = {
    "Model_Validation_Classification": Model_Validation_Classification
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Model_Validation_Classification": "Model Validation(Classification)"
} 