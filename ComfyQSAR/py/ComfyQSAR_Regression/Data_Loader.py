import pandas as pd
import os
from rdkit import Chem
# from ..utils.progress_utils import create_text_container # Now imported below

from server import PromptServer
import time # time ëª¨ë“ˆ ì¶”ê°€

# WebSocket ì´ë²¤íŠ¸ ì´ë¦„ ì •ì˜ (ëª¨ë“  QSAR ë…¸ë“œì—ì„œ ê³µí†µ ì‚¬ìš©)
QSAR_PROGRESS_EVENT = "qsar-desc-calc-progress" # ì´ë¦„ì„ ì¢€ ë” ë²”ìš©ì ìœ¼ë¡œ ë³€ê²½ (ì„ íƒì )
# ë˜ëŠ” ê¸°ì¡´ ì´ë¦„ ìœ ì§€: QSAR_DESC_CALC_PROGRESS_EVENT = "qsar-desc-calc-progress"

def send_progress(message, progress=None, node_id=None):
    """
    ì§€ì •ëœ ë©”ì‹œì§€ì™€ ì§„í–‰ë¥ (0-100)ì„ WebSocketì„ í†µí•´ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ì†¡í•˜ê³ ,
    ì¤‘ê°„ ë‹¨ê³„ ì—…ë°ì´íŠ¸ ì‹œ ì§§ì€ ì§€ì—° ì‹œê°„ì„ ì¶”ê°€í•˜ì—¬ UIì—ì„œ ë³¼ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    Args:
        message (str): í‘œì‹œí•  ìƒíƒœ ë©”ì‹œì§€.
        progress (Optional[float]): 0ë¶€í„° 100 ì‚¬ì´ì˜ ì§„í–‰ë¥  ê°’.
        node_id (Optional[str]): íŠ¹ì • ë…¸ë“œë¥¼ ëŒ€ìƒìœ¼ë¡œ í•  ê²½ìš° ë…¸ë“œ ID.
    """
    payload = {"text": [message]}
    is_intermediate_update = False # ì¤‘ê°„ ì—…ë°ì´íŠ¸ ì—¬ë¶€ í”Œë˜ê·¸

    if progress is not None:
        # ì§„í–‰ë¥  ê°’ì„ 0ê³¼ 100 ì‚¬ì´ë¡œ ì œí•œí•˜ê³  ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ (ì„ íƒì )
        clamped_progress = max(0.0, min(100.0, float(progress)))
        payload['progress'] = round(clamped_progress, 1)
        # 100%ê°€ ì•„ë‹Œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ì¸ì§€ í™•ì¸
        if clamped_progress < 100:
            is_intermediate_update = True

    # node ID ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í•„í„°ë§ ì‹œ ì‚¬ìš© ê°€ëŠ¥)
    # if node_id: payload['node'] = node_id

    try:
        # PromptServer ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ë™ê¸°ì ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡
        PromptServer.instance.send_sync(QSAR_PROGRESS_EVENT, payload)

        # ì¤‘ê°„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ í›„ ì§§ì€ ì§€ì—° ì‹œê°„ ì¶”ê°€ (0.2ì´ˆ)
        # ìµœì¢…(100%) ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” ì§€ì—° ì—†ìŒ
        if is_intermediate_update:
            time.sleep(0.2) # 0.2ì´ˆ ëŒ€ê¸°

    except Exception as e:
        print(f"[ComfyQSAR Progress Util] WebSocket ì „ì†¡ ì˜¤ë¥˜: {e}")

# í•„ìš”ì— ë”°ë¼ ë‹¤ë¥¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ ê°€ëŠ¥ (ì˜ˆ: ì‹œê°„ í¬ë§·íŒ… ë“±) 

# í…ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ìƒì„± í—¬í¼ í•¨ìˆ˜
def create_text_container(*lines):
    # ê°€ì¥ ê¸´ ë¼ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„ì„  ê¸¸ì´ ê²°ì •
    max_length = max(len(line) for line in lines)
    separator = "=" * max_length
    
    # ì²« êµ¬ë¶„ì„  ì¶”ê°€
    result = [separator]
    
    # ê° ë¼ì¸ ì¶”ê°€
    for line in lines:
        result.append(line)
    
    # ë§ˆì§€ë§‰ êµ¬ë¶„ì„  ì¶”ê°€
    result.append(separator)
    
    # ì¤„ë°”ê¿ˆìœ¼ë¡œ ì¡°ì¸
    return "\n".join(result)

class Data_Loader_Regression:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "smiles_file_path": ("STRING", {"default": "smiles.tsv"}), # Added default examples
                "biological_value_file_path": ("STRING", {"default": "values.tsv"}),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("COMBINED_DATA_PATH",) # Updated name
    FUNCTION = "load_data"
    CATEGORY = "QSAR/REGRESSION/LOAD & STANDARDIZATION"
    OUTPUT_NODE = True

    def load_data(self, smiles_file_path, biological_value_file_path):
        send_progress("ğŸš€ Starting Regression Data Loading & Merging...", 0)
        output_dir = "QSAR/Load_Data"
        combined_df_path = "" # Initialize path

        try:
            os.makedirs(output_dir, exist_ok=True)
            send_progress(f"ğŸ“‚ Output directory checked/created: {output_dir}", 5)

            # Load SMILES file
            send_progress(f"â³ Loading SMILES data from: {smiles_file_path}", 10)
            if not os.path.exists(smiles_file_path):
                raise FileNotFoundError(f"SMILES file not found: {smiles_file_path}")
            # Assuming tab-separated, no header
            smiles_df = pd.read_csv(smiles_file_path, sep="\t", header=None, names=["SMILES"])
            send_progress(f"   Loaded {len(smiles_df)} SMILES records.", 25)

            # Load Value file
            send_progress(f"â³ Loading biological value data from: {biological_value_file_path}", 30)
            if not os.path.exists(biological_value_file_path):
                raise FileNotFoundError(f"Biological value file not found: {biological_value_file_path}")
            # Assuming tab-separated, no header
            value_df = pd.read_csv(biological_value_file_path, sep="\t", header=None, names=["value"])
            send_progress(f"   Loaded {len(value_df)} value records.", 45)

            # Check row count match
            send_progress("âš–ï¸ Checking row count consistency...", 50)
            if len(smiles_df) != len(value_df):
                raise ValueError(f"Mismatched row count between SMILES ({len(smiles_df)}) and values ({len(value_df)})!")
            send_progress("   Row counts match.", 60)

            # Combine data
            send_progress("âš™ï¸ Merging SMILES and value data...", 65)
            combined_df = pd.concat([smiles_df, value_df], axis=1)
            send_progress("   Data merged.", 75)

            # Save combined data
            send_progress("ğŸ’¾ Saving combined data...", 80)
            combined_df_path = os.path.join(output_dir, "regression_combined_input_data.csv")
            combined_df.to_csv(combined_df_path, index=False)
            send_progress(f"   Combined data saved to: {combined_df_path}", 85)

            # Generate summary
            send_progress("ğŸ“ Generating summary...", 95)
            text_container_content = create_text_container(
                "ğŸ”¹ **Regression Data Loading & Merging Completed!** ğŸ”¹",
                f"SMILES File: {os.path.basename(smiles_file_path)} ({len(smiles_df)} records)",
                f"Values File: {os.path.basename(biological_value_file_path)} ({len(value_df)} records)",
                f"Total Merged Records: {len(combined_df)}",
                f"Output File: {combined_df_path}"
            )
            send_progress("ğŸ‰ Data loading and merging finished successfully!", 100)

            return {"ui": {"text": text_container_content},
                    "result": (str(combined_df_path),)}

        except FileNotFoundError as fnf_e:
            error_msg = f"âŒ File Not Found Error: {str(fnf_e)}. Please check input file paths."
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}
        except ValueError as ve:
            error_msg = f"âŒ Value Error: {str(ve)}."
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}
        except Exception as e:
            error_msg = f"âŒ An unexpected error occurred during data loading/merging: {str(e)}"
            import traceback
            error_msg += f"\nTraceback:\n{traceback.format_exc()}"
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}


class Standardization_Regression:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "input_data_path": ("STRING",), # Changed name for clarity
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("STANDARDIZED_DATA_PATH",) # Updated name
    FUNCTION = "standardize_data"
    CATEGORY = "QSAR/REGRESSION/LOAD & STANDARDIZATION"
    OUTPUT_NODE = True

    def standardize_data(self, input_data_path):
        send_progress("ğŸš€ Starting Regression Data Standardization...", 0)
        METAL_IONS = { # Define METAL_IONS inside the method
            'Li', 'Be', 'Na', 'Mg', 'Al', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',
            'Ga', 'Ge', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn',
            'Sb', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm',
            'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'Pa', 'U'
        }
        output_dir = "QSAR/Standardization"
        filtered_data_path = ""

        try:
            os.makedirs(output_dir, exist_ok=True)
            send_progress(f"ğŸ“‚ Output directory checked/created: {output_dir}", 5)

            send_progress(f"â³ Loading data from: {input_data_path}", 10)
            data = pd.read_csv(input_data_path)
            original_count = len(data)
            send_progress(f"   Data loaded ({original_count} records).", 15)

            send_progress("âš™ï¸ Checking for required columns ('SMILES', 'value')...", 20)
            if "SMILES" not in data.columns or "value" not in data.columns:
                raise ValueError("Required columns 'SMILES' and/or 'value' not found in the input data!")
            send_progress("   Required columns found.", 25)

            # Internal function for filtering
            def filter_molecule(mol):
                if mol is None: return False
                atom_symbols = {atom.GetSymbol() for atom in mol.GetAtoms()}
                if not atom_symbols or atom_symbols.issubset(METAL_IONS): return False
                if len(Chem.GetMolFrags(mol)) > 1: return False
                return True

            send_progress("ğŸ§ª Standardizing molecules (checking validity, removing metals, fragments)...", 30)
            data["RDKit_Mol"] = data["SMILES"].apply(lambda x: Chem.MolFromSmiles(x) if pd.notna(x) else None)
            filtered_data = data[data["RDKit_Mol"].apply(filter_molecule)].copy() # Filter and copy
            filtered_data.drop(columns=["RDKit_Mol"], inplace=True)
            filtered_count = len(filtered_data)
            removed_count = original_count - filtered_count
            send_progress(f"   Standardization complete. Kept {filtered_count} records, removed {removed_count}.", 75)


            send_progress("ğŸ’¾ Saving standardized data...", 85)
            filtered_data_path = os.path.join(output_dir, f"regression_standardized_{original_count}_to_{filtered_count}.csv")
            filtered_data.to_csv(filtered_data_path, index=False)
            send_progress(f"   Standardized data saved to: {filtered_data_path}", 90)

            send_progress("ğŸ“ Generating summary...", 95)
            text_container_content = create_text_container(
                "ğŸ”¹ **Regression Data Standardization Completed!** ğŸ”¹",
                f"Input File: {os.path.basename(input_data_path)} ({original_count} records)",
                f"Records Kept: {filtered_count}",
                f"Records Removed (Invalid SMILES, Metals, Fragments): {removed_count}",
                f"Output File: {filtered_data_path}"
            )
            send_progress("ğŸ‰ Standardization finished successfully!", 100)

            return {"ui": {"text": text_container_content},
                    "result": (str(filtered_data_path),)}

        except FileNotFoundError as fnf_e:
            error_msg = f"âŒ File Not Found Error: {str(fnf_e)}. Please check input file path."
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}
        except ValueError as ve:
            error_msg = f"âŒ Value Error: {str(ve)}."
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}
        except Exception as e:
            error_msg = f"âŒ An unexpected error occurred during standardization: {str(e)}"
            import traceback
            error_msg += f"\nTraceback:\n{traceback.format_exc()}"
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}


class Load_and_Standardize_Regression:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "smiles_file_path": ("STRING", {"default": "smiles.tsv"}),
                "biological_value_file_path": ("STRING", {"default": "values.tsv"}),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("STANDARDIZED_DATA_PATH",) # Updated name
    FUNCTION = "load_and_standardize_data"
    CATEGORY = "QSAR/REGRESSION/LOAD & STANDARDIZATION"
    OUTPUT_NODE = True

    def load_and_standardize_data(self, smiles_file_path, biological_value_file_path):
        send_progress("ğŸš€ Starting Regression Load & Standardization...", 0)
        METAL_IONS = { # Define METAL_IONS inside the method
            'Li', 'Be', 'Na', 'Mg', 'Al', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',
            'Ga', 'Ge', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn',
            'Sb', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm',
            'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'Pa', 'U'
        }
        output_dir = "QSAR/Load_and_Standardize"
        filtered_data_path = ""
        original_count, filtered_count = 0, 0

        try:
            os.makedirs(output_dir, exist_ok=True)
            send_progress(f"ğŸ“‚ Output directory checked/created: {output_dir}", 5)

            # --- Load Data Step (from Data_Loader_Regression) ---
            send_progress(f"â³ Loading SMILES data from: {smiles_file_path}", 10)
            if not os.path.exists(smiles_file_path): raise FileNotFoundError(f"SMILES file not found: {smiles_file_path}")
            smiles_df = pd.read_csv(smiles_file_path, sep="\t", header=None, names=["SMILES"])
            send_progress(f"   Loaded {len(smiles_df)} SMILES records.", 15)

            send_progress(f"â³ Loading biological value data from: {biological_value_file_path}", 20)
            if not os.path.exists(biological_value_file_path): raise FileNotFoundError(f"Value file not found: {biological_value_file_path}")
            value_df = pd.read_csv(biological_value_file_path, sep="\t", header=None, names=["value"])
            send_progress(f"   Loaded {len(value_df)} value records.", 25)

            send_progress("âš–ï¸ Checking row count consistency...", 30)
            if len(smiles_df) != len(value_df): raise ValueError(f"Mismatched rows: SMILES ({len(smiles_df)}) vs values ({len(value_df)})!")
            send_progress("   Row counts match.", 35)

            send_progress("âš™ï¸ Merging SMILES and value data...", 40)
            combined_df = pd.concat([smiles_df, value_df], axis=1)
            original_count = len(combined_df)
            send_progress(f"   Data merged ({original_count} records).", 45)
            # --- End Load Data Step ---

            # --- Standardization Step (from Standardization_Regression) ---
            send_progress("âš™ï¸ Checking for required columns ('SMILES', 'value')...", 50)
            if "SMILES" not in combined_df.columns or "value" not in combined_df.columns:
                 raise ValueError("Internal Error: Required columns 'SMILES'/'value' missing after merge!")
            send_progress("   Required columns present.", 55)

            def filter_molecule(mol): # Internal function
                if mol is None: return False
                atom_symbols = {atom.GetSymbol() for atom in mol.GetAtoms()}
                if not atom_symbols or atom_symbols.issubset(METAL_IONS): return False
                if len(Chem.GetMolFrags(mol)) > 1: return False
                return True

            send_progress("ğŸ§ª Standardizing molecules...", 60)
            combined_df["RDKit_Mol"] = combined_df["SMILES"].apply(lambda x: Chem.MolFromSmiles(x) if pd.notna(x) else None)
            filtered_data = combined_df[combined_df["RDKit_Mol"].apply(filter_molecule)].copy()
            filtered_data.drop(columns=["RDKit_Mol"], inplace=True)
            filtered_count = len(filtered_data)
            removed_count = original_count - filtered_count
            send_progress(f"   Standardization complete. Kept {filtered_count} records, removed {removed_count}.", 85)
            # --- End Standardization Step ---

            # --- Save Final Data ---
            send_progress("ğŸ’¾ Saving standardized data...", 90)
            filtered_data_path = os.path.join(output_dir, f"regression_loaded_standardized_{original_count}_to_{filtered_count}.csv")
            filtered_data.to_csv(filtered_data_path, index=False)
            send_progress(f"   Standardized data saved to: {filtered_data_path}", 94)

            # --- Generate Summary ---
            send_progress("ğŸ“ Generating summary...", 95)
            text_container_content = create_text_container(
                "ğŸ”¹ **Regression Load & Standardization Completed!** ğŸ”¹",
                f"Input SMILES: {os.path.basename(smiles_file_path)}",
                f"Input Values: {os.path.basename(biological_value_file_path)}",
                f"Original Records: {original_count}",
                f"Records Kept After Standardization: {filtered_count}",
                f"Records Removed: {removed_count}",
                f"Output File: {filtered_data_path}"
            )
            send_progress("ğŸ‰ Load & Standardization finished successfully!", 100)

            return {"ui": {"text": text_container_content},
                    "result": (str(filtered_data_path),)}

        except FileNotFoundError as fnf_e:
            error_msg = f"âŒ File Not Found Error: {str(fnf_e)}."
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}
        except ValueError as ve:
            error_msg = f"âŒ Value Error: {str(ve)}."
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}
        except Exception as e:
            error_msg = f"âŒ An unexpected error occurred: {str(e)}"
            import traceback
            error_msg += f"\nTraceback:\n{traceback.format_exc()}"
            send_progress(error_msg)
            return {"ui": {"text": create_text_container(error_msg)}, "result": (",")}


NODE_CLASS_MAPPINGS = {
    "Data_Loader_Regression": Data_Loader_Regression,
    "Standardization_Regression": Standardization_Regression,
    "Load_and_Standardize_Regression": Load_and_Standardize_Regression,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Data_Loader_Regression": "Data Loader (Regression)", # Updated
    "Standardization_Regression": "Standardization (Regression)", # Updated
    "Load_and_Standardize_Regression": "Load & Standardization (Regression)", # Updated
}